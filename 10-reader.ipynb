{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game data\n",
    "\n",
    "Game data seems to be contained in `reader*.zbd` archives. Luckily, they use the same file table at the end of the archive, which we know how to extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vulture_prints.zrd\n",
      "thor_prints.zrd\n",
      "supernova_prints.zrd\n",
      "sunder_prints.zrd\n",
      "strider_prints.zrd\n",
      "effects.zrd\n",
      "dialog.zrd\n",
      "commonAnim.zrd\n",
      "camera.zrd\n",
      "briefing.zrd\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from struct import Struct, unpack_from\n",
    "\n",
    "ARCHIVE_FOOTER = Struct(\"<2I\")\n",
    "ARCHIVE_RECORD = Struct(\"<2I64s76x\")\n",
    "\n",
    "\n",
    "def extract_archive(data):\n",
    "    offset = len(data) - ARCHIVE_FOOTER.size\n",
    "    _, count = ARCHIVE_FOOTER.unpack_from(data, offset)\n",
    "    for _ in range(count):\n",
    "        offset -= ARCHIVE_RECORD.size  # walk the table backwards\n",
    "        start, length, name = ARCHIVE_RECORD.unpack_from(data, offset)\n",
    "        name = name.rstrip(b\"\\x00\").decode(\"ascii\")\n",
    "        yield name, data[start : start + length]\n",
    "\n",
    "\n",
    "data = Path(\"install/v1.0-us-post/zbd/reader.zbd\").read_bytes()\n",
    "reader = dict(extract_archive(data))\n",
    "reader_names = list(reader.keys())\n",
    "print(\"\\n\".join(reader_names[:5] + reader_names[-5:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(name.endswith(\".zrd\") for name in reader.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "UINT32 = Struct(\"<I\")\n",
    "FLOAT = Struct(\"<f\")\n",
    "\n",
    "\n",
    "def read(zrd):\n",
    "    offset = 0\n",
    "\n",
    "    def _read_node(zrd):\n",
    "        nonlocal offset\n",
    "        node_type, = UINT32.unpack_from(zrd, offset)\n",
    "        offset += UINT32.size\n",
    "        \n",
    "        # uint32\n",
    "        if node_type == 1:\n",
    "            value, = UINT32.unpack_from(zrd, offset)\n",
    "            offset += UINT32.size\n",
    "            return value\n",
    "    \n",
    "        # float\n",
    "        if node_type == 2:\n",
    "            value, = FLOAT.unpack_from(zrd, offset)\n",
    "            offset += FLOAT.size\n",
    "            return value\n",
    "        \n",
    "        # string\n",
    "        if node_type == 3:\n",
    "            count, = UINT32.unpack_from(zrd, offset)\n",
    "            offset += UINT32.size\n",
    "            value = zrd[offset : offset + count].decode(\"ascii\")\n",
    "            offset += count\n",
    "            return value\n",
    "        \n",
    "        # list\n",
    "        if node_type == 4:\n",
    "            count, = UINT32.unpack_from(zrd, offset)\n",
    "            offset += UINT32.size\n",
    "            \n",
    "            # count is one bigger, because in the code this first item\n",
    "            # of the list stores the item count\n",
    "            count -= 1\n",
    "            \n",
    "            if count == 0:\n",
    "                return None\n",
    "            \n",
    "            # special case to aid readability\n",
    "            if count == 1:\n",
    "                return _read_node(zrd)\n",
    "\n",
    "            values = [_read_node(zrd) for i in range(count)]\n",
    "            \n",
    "            # special munging to turn a list of keys and values into a dict\n",
    "            is_even = count % 2 == 0\n",
    "            has_keys = all(isinstance(s, str) for s in values[::2])\n",
    "            if is_even and has_keys:\n",
    "                it = iter(values)\n",
    "                values = dict(zip(it, it))\n",
    "\n",
    "            return values\n",
    "\n",
    "        raise ValueError(f\"Invalid reader node type {node_type} in zRdrRead()\")\n",
    "    \n",
    "    ret = _read_node(zrd)\n",
    "    assert offset >= len(zrd)\n",
    "    return ret\n",
    "\n",
    "base_path = Path.cwd() / \"reader\"\n",
    "for name, zrd in reader.items():\n",
    "    # print(name)\n",
    "    json_path = base_path / name.replace(\".zrd\", \".json\")\n",
    "    with json_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(read(zrd), f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As much as it helped with the 3D data to work from the decompiled source, here's it's the other way around. This data is highly structured, so can easily be analysed. The instructions are extremely difficult to figure out, and most of the deserialisation code seems to be hard-coded/baked in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next up\n",
    "\n",
    "[The game's internal interpreter files](11-interp.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
